{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install face_recognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdm7Tm4QmRH2",
        "outputId": "4a36cfd2-8158-4464-9111-cf4c1ea13adb"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: face_recognition in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (0.3.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyheif"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VEUD1TU_zFg",
        "outputId": "7dfe55ab-8af4-454c-aeab-9608a948406b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyheif in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyheif) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.0->pyheif) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUkHPj2h4Hao",
        "outputId": "ce9d5e6f-720d-46dd-cb18-287cd423750a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# root_path = '/content/drive/MyDrive/SCU/ML/Project/'\n",
        "root_path = '/content/drive/MyDrive/COEN240/'\n",
        "\n",
        "def get_training_set_path():\n",
        "  return os.path.join(root_path, 'training')\n",
        "\n",
        "def get_testing_set_path():\n",
        "  return os.path.join(root_path, 'test')\n",
        "\n",
        "def get_test_labels_path():\n",
        "  return os.path.join(get_testing_set_path(), 'labels.txt')\n",
        "\n",
        "def get_trained_results_path(trained):\n",
        "  return '/content/trained_results' if trained else os.path.join(root_path, 'trained_results')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u8VA7UBPBHZ",
        "outputId": "b2d69456-f019-4405-e5bc-9fc69b6009bf"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN training and inferencing\n",
        "\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def cosine_similarity(point1, point2):\n",
        "    dot_product = np.dot(point1, point2)\n",
        "    norm_point1 = np.linalg.norm(point1)\n",
        "    norm_point2 = np.linalg.norm(point2)\n",
        "    similarity = dot_product / (norm_point1 * norm_point2)\n",
        "    return similarity\n",
        "\n",
        "def cosine_distance(point1, point2):\n",
        "    similarity = cosine_similarity(point1, point2)\n",
        "    distance = 1 - similarity\n",
        "    return distance\n",
        "\n",
        "def euclidean_distance(point1, point2):\n",
        "  return np.linalg.norm(point1 - point2)\n",
        "\n",
        "def knn_inferencing(dataset, dataset_labels, testing_point, k=1):\n",
        "  distances = []\n",
        "\n",
        "  x_test = testing_point\n",
        "\n",
        "  for each in range(len(dataset)):\n",
        "    x_train = dataset[each]\n",
        "    y_train = dataset_labels[each]\n",
        "    distance = cosine_distance(x_train, x_test)\n",
        "    distances.append((distance, y_train))\n",
        "\n",
        "  sorted_distances = sorted(distances, key=lambda x: x[0])[:k]\n",
        "  k_nearest_labels = [label for _, label in sorted_distances]\n",
        "  label_counts = Counter(k_nearest_labels)\n",
        "  majority_label = label_counts.most_common(1)[0][0]\n",
        "\n",
        "  return majority_label\n"
      ],
      "metadata": {
        "id": "e5VunQYyw_Ys"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM Classifier\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def get_svm_classifier():\n",
        "  data = np.loadtxt('/content/trained_data', delimiter=',', dtype=str)\n",
        "  encodings = data[:, :-1].astype(float).tolist()\n",
        "  labels = data[:, -1].tolist()\n",
        "\n",
        "  label_encoder = LabelEncoder()\n",
        "  numeric_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(encodings, numeric_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "  svm_classifier = SVC(kernel='linear', decision_function_shape='ovr', random_state=42)\n",
        "\n",
        "  svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "  return svm_classifier, label_encoder\n"
      ],
      "metadata": {
        "id": "JhWBhDGT4Fu6"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayesian Classifier\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def get_nb_classifier():\n",
        "  data = np.loadtxt('/content/trained_data', delimiter=',', dtype=str)\n",
        "  encodings = data[:, :-1].astype(float).tolist()\n",
        "  labels = data[:, -1].tolist()\n",
        "\n",
        "  label_encoder = LabelEncoder()\n",
        "  numeric_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(encodings, numeric_labels, test_size=0.1, random_state=42)\n",
        "\n",
        "  nb_classifier = GaussianNB()\n",
        "\n",
        "  nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "  return nb_classifier, label_encoder\n"
      ],
      "metadata": {
        "id": "wmlInYvj7c5j"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def get_rf_classifier():\n",
        "  data = np.loadtxt('/content/trained_data', delimiter=',', dtype=str)\n",
        "  encodings = data[:, :-1].astype(float).tolist()\n",
        "  labels = data[:, -1].tolist()\n",
        "\n",
        "  label_encoder = LabelEncoder()\n",
        "  numeric_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(encodings, numeric_labels, test_size=0.1, random_state=42)\n",
        "\n",
        "  rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "  rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "  return rf_classifier, label_encoder\n"
      ],
      "metadata": {
        "id": "QSYl8ZQm8uU5"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model = 'knn'):\n",
        "  function_dict = {\n",
        "    'knn': None,\n",
        "    'svm': 'get_svm_classifier',\n",
        "    'nb': 'get_nb_classifier',\n",
        "    'rf': 'get_rf_classifier'\n",
        "  }\n",
        "\n",
        "  selected_model = function_dict.get(model, None)\n",
        "  if selected_model:\n",
        "    return selected_model()\n",
        "  else:\n",
        "    return \"\"\n",
        "\n",
        "def get_label(trained_model, label_encoder, encoding):\n",
        "  encoding = np.array(encoding).reshape(1, -1)\n",
        "  predicted_label = trained_model.predict(encoding)[0]\n",
        "\n",
        "  return label_encoder.inverse_transform([predicted_label])[0]"
      ],
      "metadata": {
        "id": "8hF0pe6Gw247"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import face_recognition\n",
        "import cv2\n",
        "\n",
        "def get_normalized_image(image):\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  resized_image = cv2.resize(gray, (224, 224))\n",
        "  return resized_image\n",
        "\n",
        "def locations_exists(path):\n",
        "  return face_recognition.face_locations(face_recognition.load_image_file(path)) if True else False\n",
        "\n",
        "def get_face_encoding(path):\n",
        "  image = face_recognition.load_image_file(path)\n",
        "  face_locations = face_recognition.face_locations(image)\n",
        "  if face_locations:\n",
        "    face_encoding = face_recognition.face_encodings(image, face_locations)[0]\n",
        "    return face_encoding\n",
        "  else:\n",
        "    return [False]\n"
      ],
      "metadata": {
        "id": "KtpwPARzJkHM"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import pyheif\n",
        "from PIL import Image\n",
        "\n",
        "def is_an_image_file(path):\n",
        "  return (path.lower().endswith('.jpeg') and locations_exists(path)) if True else False\n",
        "\n",
        "def convert_heic_to_jpeg(heic_file_path):\n",
        "  heif_file = pyheif.read(heic_file_path)\n",
        "  image_data = heif_file.data\n",
        "\n",
        "  pil_image = Image.frombytes(\n",
        "            heif_file.mode,\n",
        "            heif_file.size,\n",
        "            image_data,\n",
        "            \"raw\",\n",
        "            heif_file.mode,\n",
        "            heif_file.stride,\n",
        "  )\n",
        "  jpg_file_path = os.path.splitext(heic_file_path)[0] + '.jpeg'\n",
        "  pil_image.save('/content/img', format=\"JPEG\")\n",
        "  shutil.move(heic_file_path, jpg_file_path)\n",
        "\n",
        "def correct_image_formats(path):\n",
        "  if os.path.isdir(path):\n",
        "    for file in os.listdir(path):\n",
        "      correct_image_formats(os.path.join(path, file))\n",
        "  elif path.lower().endswith('.heic'):\n",
        "    convert_heic_to_jpeg(path)\n",
        "\n",
        "def get_encodings_and_labels(path, train_percentage = 80, *, for_validation = False):\n",
        "  encodings = []\n",
        "  labels = []\n",
        "  for name in os.listdir(path):\n",
        "    path_with_name = os.path.join(path, name)\n",
        "    if \".\" in path_with_name:\n",
        "      continue\n",
        "    file_list = os.listdir(path_with_name)\n",
        "    train_until = int((train_percentage / 100) * len(file_list))\n",
        "    if for_validation:\n",
        "      file_list = file_list[train_until:]\n",
        "    else:\n",
        "      file_list = file_list[:train_until]\n",
        "\n",
        "    for image_file in file_list:\n",
        "      path_with_image = os.path.join(path_with_name, image_file)\n",
        "      if not os.path.isdir(path_with_image) and not path_with_image.lower().endswith('.heic'):\n",
        "        # print(\"path : \", path_with_image)\n",
        "        encoding = get_face_encoding(path_with_image)\n",
        "        if all(encoding):\n",
        "          encodings.append(encoding)\n",
        "          labels.append(name)\n",
        "\n",
        "  return encodings, labels\n",
        "\n",
        "def save_encodings_and_labels_to_file(encodings, labels, file_path):\n",
        "  data = np.column_stack((encodings, labels))\n",
        "  np.savetxt(file_path, data, fmt='%s', delimiter=',')\n",
        "\n",
        "def read_encodings_and_labels_from_file(file_path):\n",
        "  data = np.loadtxt(file_path, delimiter=',', dtype=str)\n",
        "  encodings = data[:, :-1].astype(float).tolist()\n",
        "  labels = data[:, -1].tolist()\n",
        "  return encodings, labels"
      ],
      "metadata": {
        "id": "Pvy6gHGO9Nxb"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "trained = False\n",
        "\n",
        "def train(train_percentage = 80):\n",
        "  global trained\n",
        "  training_set_encodings, training_set_labels = get_encodings_and_labels(get_training_set_path(), train_percentage)\n",
        "  trained = True\n",
        "  save_encodings_and_labels_to_file(training_set_encodings, training_set_labels, get_trained_results_path(trained))\n",
        "  print(\"training set encodings length: \", len(training_set_encodings))\n",
        "  print(\"training set labels length: \", len(training_set_labels))\n",
        "  train_details = {'train_percentage': train_percentage, 'training_set_encodings': training_set_encodings, 'training_set_labels': training_set_labels}\n",
        "  return train_details\n",
        "\n",
        "def validate(train_details):\n",
        "  train_percentage = train_details['train_percentage']\n",
        "  training_set_encodings = train_details['training_set_encodings']\n",
        "  training_set_labels = train_details['training_set_labels']\n",
        "  validation_set_encodings, validation_set_labels = get_encodings_and_labels(get_training_set_path(), train_percentage, for_validation = True)\n",
        "  correctly_classified_count = 0\n",
        "  for each in range(len(validation_set_encodings)):\n",
        "    test_encoding = validation_set_encodings[each]\n",
        "    knn_label = knn_inferencing(training_set_encodings, training_set_labels, test_encoding)\n",
        "    # print(\"knn label = \", knn_label)\n",
        "    # print(\"validation label = \", validation_set_labels[each])\n",
        "    if (knn_label == validation_set_labels[each]):\n",
        "      correctly_classified_count = correctly_classified_count + 1\n",
        "  accuracy = (correctly_classified_count / len(validation_set_encodings)) * 100\n",
        "  return accuracy\n",
        "\n",
        "def extract_number_from_path(path):\n",
        "    match = re.search(r'(\\d+)_\\d+.jpeg', path)\n",
        "    return int(match.group(1)) - 1\n",
        "\n",
        "def extract_names_from_labels(path):\n",
        "  names = []\n",
        "  with open(path, 'r') as file:\n",
        "    for line in file:\n",
        "        _, name = line.strip().split(maxsplit=1)\n",
        "        names.append(name)\n",
        "  return names\n",
        "\n",
        "def get_labels_dict(path):\n",
        "  with open(path, 'r') as file:\n",
        "    labels_dict = {}\n",
        "\n",
        "    for line in file:\n",
        "      image_name, person_name = line.strip().split()\n",
        "      image_name = image_name.split('.')[0]\n",
        "      labels_dict[image_name] = person_name\n",
        "\n",
        "  return labels_dict\n",
        "\n",
        "def test():\n",
        "  correctly_classified_count = 0\n",
        "  test_set_count = 0\n",
        "  training_set_encodings, training_set_labels = read_encodings_and_labels_from_file(get_trained_results_path(trained))\n",
        "  labels_dict = get_labels_dict(get_test_labels_path())\n",
        "  names = extract_names_from_labels(get_test_labels_path())\n",
        "\n",
        "  for image_file in os.listdir(get_testing_set_path()):\n",
        "    path_with_image = os.path.join(get_testing_set_path(), image_file)\n",
        "    if not os.path.isdir(path_with_image):\n",
        "      if is_an_image_file(path_with_image):\n",
        "        test_set_count = test_set_count + 1\n",
        "        encoding = get_face_encoding(path_with_image)\n",
        "        knn_label = knn_inferencing(training_set_encodings, training_set_labels, encoding)\n",
        "        actual_label = labels_dict[image_file.split('.')[0]]\n",
        "\n",
        "        if actual_label.lower().replace(\" \", \"\") == knn_label.lower().replace(\" \", \"\"):\n",
        "          correctly_classified_count = correctly_classified_count + 1\n",
        "\n",
        "  accuracy = (correctly_classified_count / test_set_count) * 100\n",
        "  return accuracy\n",
        "\n",
        "# Training runs for about 3-5 minutes\n",
        "# Comment the 3 lines below to test directly using the trained results\n",
        "# Upload the 'trained_results' file (zipped along with the code) to the drive such that\n",
        "# path of 'trained_results' is /content/drive/MyDrive/COEN240/training/trained_results\n",
        "# ---------------------- Comment below lines to directly test --------------------------\n",
        "# --------- MAKE SURE TO UPLOAD THE 'trained_results' FILE TO THE DRIVE ----------------\n",
        "train_details = train()\n",
        "accuracy = validate(train_details)\n",
        "print(\"validation accuracy: \", accuracy)\n",
        "# ---------------------- Comment above lines to directly test --------------------------\n",
        "\n",
        "print(\"testing accuracy: \", test())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUT4VEPQL9g3",
        "outputId": "d7ffa922-6dc0-4e26-e9f1-251a03bc64e9"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training set encodings length:  166\n",
            "training set labels length:  166\n",
            "validation accuracy:  100.0\n",
            "testing accuracy:  100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "tD2y9NnKoiNS"
      }
    }
  ]
}